# AGORA

### Collective intelligence for the governance problems no one should solve alone.

---

> *In ancient Athens, the Agora was not a building. It was an agreement â€” that any citizen could stand in the open square, present an argument, and have it weighed on its merits. No rank. No privilege. Just the strength of your reasoning.*
>
> *Security governance deserves the same promise.*

---

## The Problem No One Talks About

Every day, a CISO makes decisions that ripple across millions of lives. Block this domain. Allow that access. Override a policy because a hurricane just knocked out three data centers and the backup authentication server is in the flood zone.

These decisions are **sequential**. Each one reshapes the landscape for the next. And they happen under conditions that no policy document ever anticipated.

We write static rules for a dynamic world. We build access control systems that work perfectly â€” until the moment they encounter something extraordinary. And in that moment, the human behind the console is alone with a decision that has no good answer.

**AGORA exists because those moments shouldn't be faced alone.**

---

## What Is AGORA?

AGORA is an open-source governance engine and **Decision Arena** where security professionals, researchers, and anyone who cares about how decisions get made can come together to reason about the hardest problems in AI and security governance.

At its core, AGORA is three things:

### ğŸ›ï¸ A Governance Engine

A 6-stage pipeline that sits between your systems and your AI, enforcing access control through formal argumentation â€” not just static rules.

```
 Your System
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                             â”‚
â”‚   1. PII Scan â”€â”€â”€â”€â”€â”€â”€â”€ detect & mask        â”‚
â”‚   2. Policy Gate â”€â”€â”€â”€â”€â”€ OPA/Rego ABAC       â”‚
â”‚   3. Knowledge Hub â”€â”€â”€â”€ domain memory       â”‚
â”‚   4. Argumentation â”€â”€â”€â”€ Dung's AAF          â”‚
â”‚   5. Context Assembly â”€ prompt enrichment   â”‚
â”‚   6. Model Inference â”€â”€ risk analysis       â”‚
â”‚                                             â”‚
â”‚   Every decision logged. Every argument     â”‚
â”‚   traceable. Every override justified.      â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

When policies conflict â€” and they will â€” AGORA doesn't pick the loudest rule. It constructs a formal **argumentation framework** where arguments attack and defend each other based on evidence, strength, and context. The winning position emerges from the logic itself.

This is how Dung's Abstract Argumentation Frameworks (1995) work. This is how the Nyaya school of Indian logic formalized debate thousands of years before that. AGORA brings both traditions into your governance stack.

### âš”ï¸ A Decision Arena

The Arena is where the community comes alive. Real-world governance scenarios â€” contributed by CISOs, researchers, red teams, ethicists, anyone â€” become interactive challenges where you navigate sequential decisions under pressure.

**How it works:**

You start with a scenario. A nuclear facility's monitoring system flags a potential false positive. A pandemic response AI needs to reallocate ventilators while under cyber attack. A whistleblower's identity is about to be exposed by an automated compliance report.

Each decision you make feeds into the argumentation engine. The framework shifts. New arguments emerge. Previous certainties get defeated. You see, in real-time, how your reasoning holds up â€” not against a test suite, but against formal logic.

Your decisions are scored. Your frameworks are preserved. The community learns from every path taken.

### ğŸŒ A Research Collective

AGORA is built on the conviction that the hardest governance problems sit at the intersection of traditions no single person masters alone. We draw from:

- **Dung's AAF & ASPARTIX** â€” formal argumentation semantics (grounded, preferred, stable extensions)
- **OPA/Rego & ABAC** â€” attribute-based access control as declarative policy
- **Vedic Logic (Nyaya/Tarka)** â€” millennia of formalized debate and valid reasoning
- **Confucian Ethics** â€” role-based obligations and contextual harmony
- **Islamic Jurisprudence (Ijtihad)** â€” independent reasoning when precedent fails
- **Western Liberal Tradition** â€” rights-based frameworks and adversarial testing
- **Powell's SDAM** â€” Sequential Decision Analytics for modeling decisions that unfold over time

No single tradition has the complete answer. The governance problems of the AI age demand **multi-constitutional reasoning** â€” and AGORA is where those constitutions meet, argue, and forge something stronger together.

---

## Quick Start

### Run the Engine

```bash
git clone https://github.com/Leeladitya/agora.git
cd agora
cp .env.example .env          # add your ANTHROPIC_API_KEY
docker compose up              # starts OPA + AGORA server
```

### Try the Decision Arena

The Arena is a standalone interactive experience. Open it directly in your browser â€” no server required:

```bash
# Open the nuclear false positive scenario
open arena/agora-arena.html        # macOS
xdg-open arena/agora-arena.html   # Linux
```

Navigate 3 stages of sequential decisions under 12-minute pressure. Watch the argumentation framework shift in real-time. Export your playthrough to JSON for community analysis.

### Try the Governance Engine

The server exposes the full 6-stage pipeline via API:

```bash
# Full pipeline analysis (PII â†’ Policy â†’ Knowledge â†’ Argumentation â†’ Assembly â†’ Inference)
curl -X POST http://localhost:8787/v1/analyze \
  -H "Content-Type: application/json" \
  -d '{"content": "Contact john@example.com at 555-0123", "url": "https://example.com"}'

# Zero-cost dry run â€” stages 1-4 only, no model call
curl -X POST http://localhost:8787/v1/policy/evaluate \
  -H "Content-Type: application/json" \
  -d '{"content": "Patient MRN 12345 diagnosis: pneumonia", "url": "https://hospital.org"}'

# Check a domain's reputation from the Knowledge Hub
curl http://localhost:8787/v1/knowledge/reputation/example.com
```

### Install the Browser Extension (Firefox)

1. Navigate to `about:debugging#/runtime/this-firefox`
2. Load Temporary Add-on â†’ `extension/manifest.json`
3. Click the AGORA icon on any page â†’ **Scan & Analyze**

The extension runs the full 6-stage pipeline against any web content â€” PII detection, policy evaluation, knowledge lookup, argumentation resolution, and AI risk analysis â€” all before anything reaches the model.

---

## The Argumentation Engine

This is the heart of AGORA. When policies conflict, the engine doesn't pick winners by priority number. It reasons.

**The Rego-to-AAF Bridge** converts your policy world into a formal argumentation framework:

| Source | Becomes | Strength |
|--------|---------|----------|
| OPA deny rule | Deny argument | 0.9 |
| Critical PII (SSN, credit card) | Deny argument | 0.95 |
| OPA modification rule | Modify argument | 0.7 |
| Knowledge Hub "trusted" entry | Trust argument (attacks deny) | varies |
| Knowledge Hub "suspicious" entry | Suspicion argument (attacks allow) | varies |
| Baseline | Allow argument | 0.3 |

Stronger arguments attack weaker ones when decisions conflict. The engine computes:

- **Grounded extension** â€” the unique, most skeptical position. What survives when you doubt everything you can. This is the default for security decisions.
- **Preferred extensions** â€” maximal admissible sets. Every defensible worldview.
- **Stable extensions** â€” complete coverage. No argument left unaddressed.

The CISO sees not just a decision, but the **argument map** â€” which positions won, which were defeated, and why.

---

## Knowledge Hub

AGORA remembers. Every domain it evaluates builds a reputation over time through a persistent Knowledge Hub:

- Decisions are stored with domain, outcome, matched rules, and timestamp
- Temporal decay (1-week halflife) ensures recent knowledge weighs more than stale memory
- Domain reputations aggregate as: **trusted**, **suspicious**, **mixed**, or **unknown**
- Knowledge entries feed directly into the argumentation engine as contextual arguments

This means AGORA's second decision about a domain is better than its first. Its hundredth is better still. The system learns â€” not through opaque neural weights, but through **auditable, arguable knowledge**.

---

## Community Pillars

AGORA is not a product. It's infrastructure for collective reasoning. The community is built on five pillars:

### ğŸ“š Open Scenario Library

Anyone can contribute a governance scenario. A real incident you navigated. A hypothetical that keeps you up at night. An edge case your policy framework can't handle.

Scenarios live in `arena/scenarios/` as structured JSON. Each includes the situation, available decisions, ethical tensions, and the argumentation framework that emerges.

**[â†’ How to contribute a scenario](docs/CONTRIBUTING_SCENARIOS.md)**

### ğŸ† Decision Leaderboard

When you navigate a scenario in the Arena, your decisions are scored against formal criteria: consistency, proportionality, reversibility, auditability, and how well your argumentation framework holds under adversarial examination.

Over time, the community builds a collective picture of which governance approaches work â€” not in theory, but under pressure.

### ğŸ”¬ Research Collective

AGORA is a launchpad for research. The argumentation engine, the multi-constitutional debate mechanism, the CISO decision modeling â€” all of it is publishable, forkable, and built to be extended.

We actively seek co-authors. If you're working on formal argumentation, AI governance, ABAC, Prolog-style reasoning, or cross-cultural ethics in computing â€” this is your home.

### ğŸŒ Multi-Constitutional Debate

The hardest governance problems don't have answers within a single ethical tradition. AGORA's framework supports loading multiple "constitutions" â€” ethical frameworks drawn from different traditions â€” and letting them argue.

What does Vedic dharma say about overriding access control during an emergency (apad-dharma)? How does that argument fare against a Kantian categorical imperative? What would Islamic ijtihad conclude when no precedent exists?

These aren't academic exercises. They're the actual tensions that surface when you govern AI systems used across cultures.

### ğŸ”“ Decentralization & Open Source

AGORA's source is open. Its scenarios are open. Its argumentation frameworks are open. Because governance decisions that affect everyone should be reasoned about by everyone.

The code is MIT licensed. The scenarios are CC-BY-SA. The research is for the commons.

---

## Security Architecture

| Layer | Mechanism |
|-------|-----------|
| Authentication | Bearer token, constant-time comparison |
| Rate Limiting | Per-IP token bucket (30-60 req/min) |
| CORS | Configurable allowlist, no wildcards |
| Input Validation | Max content size enforcement |
| PII Masking | SSN, credit card, email, phone, IP detection |
| Policy Gate | OPA/Rego attribute-based access control |
| Argumentation | Formal conflict resolution via Dung's AAF |
| Audit Trail | Immutable JSONL decision log |

See [SECURITY.md](SECURITY.md) for vulnerability disclosure and full architecture.

---

## API Reference

| Method | Path | Description |
|--------|------|-------------|
| `POST` | `/v1/analyze` | Full 6-stage pipeline |
| `POST` | `/v1/policy/evaluate` | Dry-run (stages 1-4, no model call, zero cost) |
| `GET` | `/v1/policy/packs` | List policy packs |
| `POST` | `/v1/knowledge/store` | Store a knowledge entry |
| `POST` | `/v1/knowledge/query` | Query Knowledge Hub |
| `GET` | `/v1/knowledge/reputation/{domain}` | Domain reputation |
| `GET` | `/v1/knowledge/stats` | Hub statistics |
| `GET` | `/v1/audit/decisions` | Audit trail |
| `GET` | `/v1/health` | Component health |

---

## Project Structure

```
agora/
â”œâ”€â”€ server/                         # Governance Engine
â”‚   â”œâ”€â”€ app.py                      #   FastAPI, 6-stage pipeline
â”‚   â”œâ”€â”€ middleware/                  #   Auth, rate limiting, PII, OPA
â”‚   â”œâ”€â”€ knowledge/                  #   Knowledge Hub (JSONL-backed)
â”‚   â”œâ”€â”€ argumentation/              #   Dung's AAF engine + Rego bridge
â”‚   â””â”€â”€ utils/                      #   Audit logging
â”œâ”€â”€ opa/                            # Policy Layer
â”‚   â”œâ”€â”€ policies/                   #   Rego rules + tests
â”‚   â””â”€â”€ data/                       #   Domain lists, config
â”œâ”€â”€ arena/                          # Decision Arena
â”‚   â”œâ”€â”€ scenarios/                  #   Community-contributed scenarios
â”‚   â””â”€â”€ frameworks/                 #   Constitutional frameworks
â”œâ”€â”€ extension/                      # Browser Extension (Firefox)
â”‚   â”œâ”€â”€ content/                    #   DOM extraction
â”‚   â””â”€â”€ popup/                      #   UI (knowledge + argumentation)
â”œâ”€â”€ community/                      # Community Infrastructure
â”œâ”€â”€ docs/                           # Guides & research
â”œâ”€â”€ tests/                          #   65 test cases (28 pipeline + 37 SDAM)
â”œâ”€â”€ .github/workflows/ci.yml       # CI/CD pipeline
â”œâ”€â”€ Dockerfile                      # Non-root container
â”œâ”€â”€ docker-compose.yml              # OPA + AGORA orchestration
â””â”€â”€ requirements.txt                # Pinned dependencies
```

---

## Configuration

| Variable | Default | Description |
|----------|---------|-------------|
| `ANTHROPIC_API_KEY` | *(required)* | Claude API key |
| `CLAW_MODEL` | `claude-sonnet-4-5-20250514` | Model for analysis |
| `CLAW_POLICY_PACK` | `standard` | Active policy pack |
| `CLAW_API_KEYS` | *(empty = auth off)* | API keys (comma-separated) |
| `CLAW_CORS_ORIGINS` | localhost + extensions | CORS allowlist |
| `CLAW_MAX_INPUT_CHARS` | `60000` | Max input size |

---

## Development

```bash
pip install -r requirements.txt

# Run tests
pytest tests/ -v                              # 65 Python tests (28 pipeline + 37 SDAM)
opa test opa/policies/ opa/data/ -v           # 20 OPA policy tests

# Lint
ruff check server/ tests/
```

See [CONTRIBUTING.md](CONTRIBUTING.md) for the full development guide.

---

## Intellectual Lineage

AGORA stands on the shoulders of traditions that span millennia and continents:

- **Dung, P.M. (1995)** â€” "On the acceptability of arguments" â€” the foundational paper on abstract argumentation frameworks
- **Nyaya Sutras** â€” Indian logic tradition formalizing valid reasoning, debate structure, and epistemic warrant
- **Open Policy Agent** â€” declarative policy-as-code that makes ABAC programmable
- **ASPARTIX** â€” answer-set programming for argumentation, computing extensions via logic programming
- **Powell's SDAM** â€” Sequential Decision Analytics and Modeling for decisions that unfold over time
- **Prolog & Logic Programming** â€” the computational tradition that makes formal reasoning executable

---

## Join the Agora

This is an open square. The only credential you need is a willingness to reason honestly.

- **Contribute a scenario** â€” What's the hardest governance decision you've faced? [Template â†’](arena/scenarios/TEMPLATE.json)
- **Challenge a framework** â€” Load a constitutional perspective and test it against the Arena
- **Publish with us** â€” We're building toward papers on formal governance. Co-authors welcome.
- **Build on the engine** â€” The argumentation core is designed to be embedded. Take it somewhere we haven't imagined.

**Start a discussion. Open an issue. Submit a scenario. The Agora is open.**

---

<p align="center">
<em>Security is not a policy. It's an argument you must win.<br/>
Win it together.</em>
</p>

---

**License:** MIT (code) Â· CC-BY-SA 4.0 (scenarios & research)

**Maintained by:** [saatvix.com](https://saatvix.com)
